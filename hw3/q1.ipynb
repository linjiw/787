{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note for question4 !\n",
    "- Please **do not** change the default variable names in this problem, as we will use them in different parts.\n",
    "- The default variables are initially set to \"None\".\n",
    "- You only need to modify code in the \"TODO\" part. We added a lot of \"assertions\" to check your code. **Do not** modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Load data and plot\n",
    "### TODO\n",
    "- Load train and test data, and split them into inputs(trainX, testX) and labels(trainY, testY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load q1_train.csv and q1_test.csv\n",
    "# Each data point has 200 features(X), followed by 1 label(Y)\n",
    "q1_train = pd.read_csv(\"q1_train.csv\").to_numpy()[1:,1:]\n",
    "q1_test = pd.read_csv(\"q1_test.csv\").to_numpy()[1:,1:]\n",
    "\n",
    "\n",
    "\n",
    "#### TODO ####\n",
    "trainX = q1_train[:,:-1]\n",
    "trainY = q1_train[:,-1]\n",
    "testX = q1_test[:,:-1]\n",
    "testY = q1_test[:,-1]\n",
    "##############\n",
    "\n",
    "assert(len(trainX.shape) == 2)\n",
    "assert(len(trainY.shape) == 1)\n",
    "assert(trainX.shape[1] == 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Write your Gaussian NB solver\n",
    "### TODO\n",
    "- Finish the myNBSolver() function. \n",
    "    - Compute P(y == 0) and P(y == 1), saved in \"py0\" and \"py1\"\n",
    "    - Compute mean/variance of trainX for both y = 0 and y = 1, saved in \"mean0\", \"var0\", \"mean1\" and \"var1\"\n",
    "        - Each of them should have shape (N_train, M), where N_train is number of train samples and M is number of features.\n",
    "    - Compute P(xi | y == 0) and P(xi | y == 1), compare and save **binary** prediction in \"train_pred\" and \"test_pred\"\n",
    "    - Compute train accuracy and test accuracy, saved in \"train_acc\" and \"test_acc\".\n",
    "    - Return train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    N_train = trainX.shape[0]\n",
    "    N_test = testX.shape[0]\n",
    "    M = trainX.shape[1]\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(y == 0) and P(y == 1)\n",
    "    y0 = np.argwhere(trainY == 0)\n",
    "    y1 = np.argwhere(trainY == 1)\n",
    "    x0 = trainX[y0]\n",
    "    \n",
    "    x1 = trainX[y1]\n",
    "    x0 = x0.squeeze()\n",
    "    x1 = x1.squeeze()\n",
    "\n",
    "    py0 = len(y0)/N_train\n",
    "    py1 = len(y1)/N_train\n",
    "    \n",
    "    ##############\n",
    "    print(\"Total probablity is %.2f. Should be equal to 1.\" %(py0 + py1))\n",
    "\n",
    "    #### TODO ####\n",
    "    # Compute mean/var for each label\n",
    "    mean0 = np.mean(x0,axis=0)\n",
    "    # print(mean0.shape)\n",
    "    mean1 = np.mean(x1,axis=0)\n",
    "    var0 = np.mean((x0-mean0)**2,axis=0)\n",
    "    var1 = np.mean((x1-mean1)**2,axis=0)\n",
    "    \n",
    "    ##############\n",
    "    assert(mean0.shape[0] == M)\n",
    "    #### TODO ####\n",
    "    # Compute P(xi|y == 0) and P(xi|y == 1), compare and make prediction\n",
    "    # This part may spend 5 - 10 minutes or even more if you use for loop, so feel free to \n",
    "    # print something (like step number) to check the progress\n",
    "    p_x_y0 = (2*np.pi*var0)**(-0.5)*np.exp(-((trainX-mean0)**2)/(2*var0))\n",
    "    p_x_y1 = (2*np.pi*var1)**(-0.5)*np.exp(-((trainX-mean1)**2)/(2*var1))\n",
    "    prod0 = py0* np.prod(p_x_y0,axis=1)\n",
    "    prod1 = py1* np.prod(p_x_y1,axis=1)\n",
    "    train_ans = np.ones(N_train)\n",
    "    pos0 = np.argwhere(prod0>prod1)\n",
    "    train_ans[pos0] = 0 \n",
    "\n",
    "    p_x_y0_test = (2*np.pi*var0)**(-0.5)*np.exp(-((testX-mean0)**2)/(2*var0))\n",
    "    p_x_y1_test = (2*np.pi*var1)**(-0.5)*np.exp(-((testX-mean1)**2)/(2*var1))\n",
    "    prod0_test = py0* np.prod(p_x_y0_test,axis=1)\n",
    "    prod1_test = py1* np.prod(p_x_y1_test,axis=1)\n",
    "    test_ans = np.ones(N_test)\n",
    "    pos0_test = np.argwhere(prod0_test>prod1_test)\n",
    "    test_ans[pos0_test] = 0 \n",
    "\n",
    "    \n",
    "    train_pred = train_ans\n",
    "    test_pred = test_ans\n",
    "\n",
    "    ##############\n",
    "    assert(train_pred[0] == 0 or train_pred[0] == 1)\n",
    "    assert(test_pred[0] == 0 or test_pred[0] == 1)\n",
    "    #### TODO ####\n",
    "    # Compute train accuracy and test accuracy\n",
    "    \n",
    "    train_acc = len(np.argwhere(train_pred==trainY))/N_train\n",
    "    test_acc = len(np.argwhere(test_pred==testY))/N_test\n",
    "    \n",
    "    ##############()\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probablity is 1.00. Should be equal to 1.\n",
      "Train accuracy is 92.22\n",
      "Test accuracy is 92.05\n"
     ]
    }
   ],
   "source": [
    "# driver to test your NB solver\n",
    "train_acc, test_acc = myNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3. Test your result using sklearn\n",
    "### TODO\n",
    "- Finish the skNBSolver() function. \n",
    "     - fit model, make prediction and return accuracy for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    #### TODO ####\n",
    "    # fit model\n",
    "    # make prediction\n",
    "    # compute accuracy\n",
    "    train = GaussianNB()\n",
    "    train.fit(trainX, trainY)\n",
    "    sk_train_acc = train.score(trainX,trainY)\n",
    "    sk_test_acc = train.score(testX,testY)\n",
    "    \n",
    "    ##############\n",
    "    return sk_train_acc, sk_test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 92.22\n",
      "Test accuracy is 92.05\n"
     ]
    }
   ],
   "source": [
    "# driver to test skNBSolver\n",
    "sk_train_acc, sk_test_acc = skNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(sk_train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(sk_test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
